# Sign-Language-to-text-Converter
This project aims to convert sign language gestures into readable text using machine learning techniques. It uses computer vision and deep learning models to recognize American Sign Language (ASL) gestures from images or video frames, and then translates them into corresponding text.

## Key Features:

Gesture recognition through Convolutional Neural Networks (CNN).
Real-time prediction of sign language gestures.
Trained using a dataset of ASL images to provide accurate text conversion.
Includes a recommendation system to suggest possible word matches for user input.

## Technologies Used:

Python for development.

1. TensorFlow and Keras for machine learning model implementation.
2. OpenCV for image processing and real-time video feed handling.

## Screnshot

![Screenshot 2024-12-23 001229](https://github.com/user-attachments/assets/4512fe21-a573-4f48-aa50-b39ca3783ed9)
![Screenshot 2024-12-23 001248](https://github.com/user-attachments/assets/ff729e34-4fdd-4182-854e-701a09991ca0)
